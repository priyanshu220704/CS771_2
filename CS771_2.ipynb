{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9UkDauX8Byb3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import time as tm\n",
        "import pickle\n",
        "import warnings\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open( \"dict\", 'r' ) as f:\n",
        "\twords = f.read().split( '\\n' )[:-1]\t\t# Omit the last line since it is empty\n",
        "\tnum_words = len( words )"
      ],
      "metadata": {
        "id": "Wdq2X6uVB8rh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_trials = 5\n",
        "t_train = 0\n",
        "m_size = 0\n",
        "t_test = 0\n",
        "prec = 0"
      ],
      "metadata": {
        "id": "UQrLNsaGB-f_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bigrams( word, lim = None ):\n",
        "  # Get all bigrams\n",
        "  bg = map( ''.join, list( zip( word, word[1:] ) ) )\n",
        "  # Remove duplicates and sort them\n",
        "  bg = sorted( set( bg ) )\n",
        "  # Make them into an immutable tuple and retain only the first few\n",
        "  return tuple( bg )[:lim]"
      ],
      "metadata": {
        "id": "MAsWDD5iChyt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramDecisionTree:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.bigram_index = None\n",
        "        self.dictionary = None\n",
        "\n",
        "    def _extract_bigrams(self, word):\n",
        "        \"\"\"Extract bigrams from a word.\"\"\"\n",
        "        return sorted(set([word[i:i+2] for i in range(len(word) - 1)]))[:5]\n",
        "\n",
        "    def _create_feature_matrix(self, words):\n",
        "        \"\"\"Create feature matrix for words based on bigrams.\"\"\"\n",
        "        bigrams = set()\n",
        "        word_bigrams = []\n",
        "\n",
        "        for word in words:\n",
        "            word_bigrams.append(self._extract_bigrams(word))\n",
        "            bigrams.update(word_bigrams[-1])\n",
        "\n",
        "        self.bigram_index = {bigram: idx for idx, bigram in enumerate(sorted(bigrams))}\n",
        "        features = np.zeros((len(words), len(self.bigram_index)))\n",
        "\n",
        "        for i, bigram_list in enumerate(word_bigrams):\n",
        "            for bigram in bigram_list:\n",
        "                features[i, self.bigram_index[bigram]] = 1\n",
        "\n",
        "        return features\n",
        "\n",
        "    def fit(self, dictionary):\n",
        "        \"\"\"Fit the decision tree model.\"\"\"\n",
        "        features = self._create_feature_matrix(dictionary)\n",
        "        labels = np.arange(len(dictionary))\n",
        "        self.model = DecisionTreeClassifier()\n",
        "        self.model.fit(features, labels)\n",
        "        self.dictionary = dictionary\n",
        "\n",
        "    def predict(self, bigram_tuple):\n",
        "        \"\"\"Predict the word based on the bigrams.\"\"\"\n",
        "        feature_vector = np.zeros((1, len(self.bigram_index)))\n",
        "        for bigram in bigram_tuple:\n",
        "            if bigram in self.bigram_index:\n",
        "                feature_vector[0, self.bigram_index[bigram]] = 1\n",
        "        predicted_index = self.model.predict(feature_vector)[0]\n",
        "        return [self.dictionary[predicted_index]]\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "def my_fit( words ):\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "\tmodel = BigramDecisionTree()\n",
        "\tmodel.fit(words)\n",
        "\t# Do not perform any file IO in your code\n",
        "\t# Use this method to train your model using the word list provided\n",
        "\n",
        "\treturn model\t\t\t\t\t# Return the trained model\n",
        "\n",
        "\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "def my_predict( model, bigram_list ):\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "\tguess_list = model.predict(bigram_list)\n",
        "\t# Do not perform any file IO in your code\n",
        "\t# Use this method to predict on a test bigram_list\n",
        "\t# Ensure that you return a list even if making a single guess\n",
        "\treturn guess_list"
      ],
      "metadata": {
        "id": "_q4Xnwgwoa3h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lim_bg = 5\n",
        "lim_out = 5\n",
        "\n",
        "t_train = 0\n",
        "t_test = 0\n",
        "m_size = 0\n",
        "\n",
        "for t in range(n_trials):\n",
        "    # Record the start time for training\n",
        "    tic = tm.perf_counter()\n",
        "\n",
        "    # Train the model\n",
        "    model = my_fit(words)\n",
        "\n",
        "    # Record the end time for training\n",
        "    toc = tm.perf_counter()\n",
        "\n",
        "    # Accumulate the training time\n",
        "    t_train += toc - tic\n",
        "\n",
        "    # Save the model to a file\n",
        "    with open(f\"model_dump_{t}.pkl\", \"wb\") as outfile:\n",
        "        pickle.dump(model, outfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    # Accumulate the size of the model\n",
        "    m_size += os.path.getsize(f\"model_dump_{t}.pkl\")\n",
        "\n",
        "    # Record the start time for testing\n",
        "    tic = tm.perf_counter()\n",
        "\n",
        "    for (i, word) in enumerate(words):\n",
        "        # Get bigrams for the word\n",
        "        bg = get_bigrams(word, lim=lim_bg)\n",
        "\n",
        "        # Make predictions using the model\n",
        "        guess_list = my_predict(model, bg)\n",
        "\n",
        "        # Limit the number of guesses to be considered\n",
        "        guess_len = len(guess_list)\n",
        "        guess_list = guess_list[:lim_out]\n",
        "\n",
        "        # Calculate precision if the word is in the guess list\n",
        "        if word in guess_list:\n",
        "            prec += 1 / guess_len\n",
        "\n",
        "    # Record the end time for testing\n",
        "    toc = tm.perf_counter()\n",
        "\n",
        "    # Accumulate the testing time\n",
        "    t_test += toc - tic\n"
      ],
      "metadata": {
        "id": "fC5OSDt9CF1p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_train /= n_trials\n",
        "m_size /= n_trials\n",
        "t_test /= n_trials\n",
        "prec /= ( n_trials * num_words )\n",
        "\n",
        "print( t_train, m_size, prec, t_test )"
      ],
      "metadata": {
        "id": "Vmub4R58CJ1E",
        "outputId": "66820c91-73b3-4ec1-ff46-b76906143621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.798775332600007 417122205.0 0.9750338687826592 0.7729708611999968\n"
          ]
        }
      ]
    }
  ]
}